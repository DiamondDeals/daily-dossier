"""
AI Recommendation Service for PersonalizedReddit
Provides AI-powered subreddit recommendations and personalized content discovery
"""

import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter
import math

from utils.logging_config import get_logger, log_performance

class AIRecommendationService:
    """
    AI-powered recommendation service for subreddit discovery and content personalization
    """
    
    def __init__(self, reddit_service, ai_service, database):
        self.reddit_service = reddit_service
        self.ai_service = ai_service
        self.database = database
        self.logger = get_logger(__name__)
        
        # User behavior tracking
        self.user_interactions = defaultdict(list)
        self.user_preferences = {}
        self.subreddit_profiles = {}
        
        # Recommendation cache
        self.recommendation_cache = {}
        self.trending_cache = {}
        self.last_analysis_update = None
        
        # Configuration
        self.config = {
            'min_confidence_threshold': 0.6,
            'max_recommendations': 20,
            'trending_window_hours': 24,
            'interaction_weight_decay': 0.9,  # Daily decay factor
            'similarity_threshold': 0.7,
            'popularity_weight': 0.3,
            'relevance_weight': 0.7
        }
        
        # Initialize subreddit analysis
        self._initialize_subreddit_profiles()
    
    def _initialize_subreddit_profiles(self):
        """Initialize profiles for known subreddits"""
        try:
            # Load existing subreddit data if available
            subreddit_file = "subreddit_master.json"
            try:
                with open(subreddit_file, 'r') as f:
                    subreddit_data = json.load(f)
                    self.logger.info(f"Loaded {len(subreddit_data)} subreddit profiles")
            except FileNotFoundError:
                subreddit_data = []
                self.logger.warning("No subreddit master file found, using defaults")
            
            # Create profiles for key business subreddits
            default_subreddits = {
                'entrepreneur': {
                    'category': 'business',
                    'business_focus': 0.9,
                    'automation_relevance': 0.7,
                    'typical_problems': ['scaling', 'automation', 'efficiency'],
                    'member_count': 1200000,
                    'activity_level': 'high'
                },
                'smallbusiness': {
                    'category': 'business',
                    'business_focus': 0.95,
                    'automation_relevance': 0.8,
                    'typical_problems': ['manual processes', 'workflow', 'growth'],
                    'member_count': 800000,
                    'activity_level': 'high'
                },
                'freelance': {
                    'category': 'business',
                    'business_focus': 0.8,
                    'automation_relevance': 0.6,
                    'typical_problems': ['client management', 'time tracking', 'invoicing'],
                    'member_count': 400000,
                    'activity_level': 'medium'
                },
                'automation': {
                    'category': 'technology',
                    'business_focus': 0.7,
                    'automation_relevance': 0.95,
                    'typical_problems': ['process automation', 'workflow optimization'],
                    'member_count': 150000,
                    'activity_level': 'medium'
                },
                'productivity': {
                    'category': 'lifestyle',
                    'business_focus': 0.6,
                    'automation_relevance': 0.7,
                    'typical_problems': ['time management', 'efficiency', 'tools'],
                    'member_count': 1000000,
                    'activity_level': 'high'
                }
            }
            
            # Merge with loaded data
            for subreddit, profile in default_subreddits.items():
                if subreddit not in self.subreddit_profiles:
                    self.subreddit_profiles[subreddit] = profile
            
            self.logger.info(f"Initialized profiles for {len(self.subreddit_profiles)} subreddits")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize subreddit profiles: {e}")
    
    @log_performance
    def generate_subreddit_recommendations(self, user_id: str = "default", count: int = 10) -> List[Dict[str, Any]]:
        """
        Generate personalized subreddit recommendations
        
        Args:
            user_id: User identifier for personalization
            count: Number of recommendations to generate
            
        Returns:
            List of recommendation dictionaries
        """
        try:
            # Check cache first
            cache_key = f"{user_id}_{count}"
            if cache_key in self.recommendation_cache:
                cached_result = self.recommendation_cache[cache_key]
                if (datetime.now() - cached_result['generated_at']).seconds < 3600:  # 1 hour cache
                    return cached_result['recommendations']
            
            # Get user preferences and interaction history
            user_profile = self._build_user_profile(user_id)
            
            # Analyze current subreddit landscape
            subreddit_analysis = self._analyze_subreddit_landscape()
            
            # Generate candidate recommendations
            candidates = self._generate_recommendation_candidates(user_profile, subreddit_analysis)
            
            # Rank and filter recommendations
            ranked_recommendations = self._rank_recommendations(candidates, user_profile)
            
            # Select top recommendations
            final_recommendations = ranked_recommendations[:count]
            
            # Add recommendation explanations
            explained_recommendations = self._add_recommendation_explanations(final_recommendations, user_profile)
            
            # Cache results
            self.recommendation_cache[cache_key] = {
                'recommendations': explained_recommendations,
                'generated_at': datetime.now()
            }
            
            self.logger.info(f"Generated {len(explained_recommendations)} recommendations for user {user_id}")
            return explained_recommendations
            
        except Exception as e:
            self.logger.error(f"Failed to generate recommendations: {e}")
            return self._get_fallback_recommendations(count)\n    \n    def _build_user_profile(self, user_id: str) -> Dict[str, Any]:\n        \"\"\"Build user profile from interaction history\"\"\"\n        try:\n            # Get user interactions from database\n            interactions = self.user_interactions.get(user_id, [])\n            \n            if not interactions:\n                # New user - return default profile\n                return self._get_default_user_profile()\n            \n            # Analyze interaction patterns\n            subreddit_frequency = Counter()\n            category_frequency = Counter()\n            topic_frequency = Counter()\n            \n            for interaction in interactions:\n                # Weight recent interactions more heavily\n                age_days = (datetime.now() - datetime.fromisoformat(interaction['timestamp'])).days\n                weight = self.config['interaction_weight_decay'] ** age_days\n                \n                subreddit = interaction.get('subreddit')\n                if subreddit:\n                    subreddit_frequency[subreddit] += weight\n                    \n                    # Add category and topics if known\n                    if subreddit in self.subreddit_profiles:\n                        profile = self.subreddit_profiles[subreddit]\n                        category_frequency[profile.get('category', 'general')] += weight\n                        \n                        for problem in profile.get('typical_problems', []):\n                            topic_frequency[problem] += weight\n            \n            # Calculate preference scores\n            total_interactions = sum(subreddit_frequency.values())\n            if total_interactions == 0:\n                return self._get_default_user_profile()\n            \n            # Normalize frequencies to preferences\n            subreddit_preferences = {\n                subreddit: count / total_interactions \n                for subreddit, count in subreddit_frequency.most_common(10)\n            }\n            \n            category_preferences = {\n                category: count / total_interactions \n                for category, count in category_frequency.most_common()\n            }\n            \n            topic_preferences = {\n                topic: count / total_interactions \n                for topic, count in topic_frequency.most_common(10)\n            }\n            \n            return {\n                'user_id': user_id,\n                'subreddit_preferences': subreddit_preferences,\n                'category_preferences': category_preferences,\n                'topic_preferences': topic_preferences,\n                'interaction_count': len(interactions),\n                'business_focus': category_preferences.get('business', 0),\n                'automation_interest': topic_preferences.get('automation', 0),\n                'last_updated': datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to build user profile: {e}\")\n            return self._get_default_user_profile()\n    \n    def _get_default_user_profile(self) -> Dict[str, Any]:\n        \"\"\"Get default user profile for new users\"\"\"\n        return {\n            'user_id': 'default',\n            'subreddit_preferences': {\n                'entrepreneur': 0.3,\n                'smallbusiness': 0.3,\n                'freelance': 0.2,\n                'automation': 0.2\n            },\n            'category_preferences': {\n                'business': 0.8,\n                'technology': 0.2\n            },\n            'topic_preferences': {\n                'automation': 0.4,\n                'scaling': 0.3,\n                'efficiency': 0.3\n            },\n            'interaction_count': 0,\n            'business_focus': 0.8,\n            'automation_interest': 0.4,\n            'last_updated': datetime.now().isoformat()\n        }\n    \n    def _analyze_subreddit_landscape(self) -> Dict[str, Any]:\n        \"\"\"Analyze the current subreddit landscape for trending topics\"\"\"\n        try:\n            # Get trending topics from recent posts\n            trending_topics = self._get_trending_topics()\n            \n            # Analyze subreddit growth and activity\n            subreddit_stats = self._get_subreddit_statistics()\n            \n            # Calculate opportunity scores for subreddits\n            opportunity_scores = self._calculate_subreddit_opportunities()\n            \n            return {\n                'trending_topics': trending_topics,\n                'subreddit_stats': subreddit_stats,\n                'opportunity_scores': opportunity_scores,\n                'analysis_timestamp': datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to analyze subreddit landscape: {e}\")\n            return {\n                'trending_topics': [],\n                'subreddit_stats': {},\n                'opportunity_scores': {},\n                'analysis_timestamp': datetime.now().isoformat()\n            }\n    \n    def _get_trending_topics(self) -> List[Dict[str, Any]]:\n        \"\"\"Get trending topics from recent posts\"\"\"\n        try:\n            # This would typically analyze recent posts across subreddits\n            # For now, return simulated trending topics\n            return [\n                {'topic': 'API Integration', 'growth_rate': 0.25, 'mentions': 156},\n                {'topic': 'Workflow Automation', 'growth_rate': 0.18, 'mentions': 234},\n                {'topic': 'Data Migration', 'growth_rate': 0.15, 'mentions': 89},\n                {'topic': 'Customer Management', 'growth_rate': 0.12, 'mentions': 167},\n                {'topic': 'Process Optimization', 'growth_rate': 0.10, 'mentions': 145}\n            ]\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to get trending topics: {e}\")\n            return []\n    \n    def _get_subreddit_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get statistics for subreddits\"\"\"\n        stats = {}\n        \n        for subreddit, profile in self.subreddit_profiles.items():\n            stats[subreddit] = {\n                'member_count': profile.get('member_count', 0),\n                'activity_level': profile.get('activity_level', 'medium'),\n                'business_focus': profile.get('business_focus', 0.5),\n                'automation_relevance': profile.get('automation_relevance', 0.5),\n                'estimated_daily_posts': self._estimate_daily_posts(profile)\n            }\n        \n        return stats\n    \n    def _estimate_daily_posts(self, profile: Dict) -> int:\n        \"\"\"Estimate daily posts for a subreddit\"\"\"\n        base_posts = {\n            'high': 100,\n            'medium': 50,\n            'low': 20\n        }\n        \n        activity_level = profile.get('activity_level', 'medium')\n        member_count = profile.get('member_count', 100000)\n        \n        # Scale based on member count\n        base = base_posts[activity_level]\n        scaling_factor = math.log10(member_count / 100000 + 1)\n        \n        return int(base * scaling_factor)\n    \n    def _calculate_subreddit_opportunities(self) -> Dict[str, float]:\n        \"\"\"Calculate business opportunity scores for subreddits\"\"\"\n        opportunity_scores = {}\n        \n        for subreddit, profile in self.subreddit_profiles.items():\n            # Base score from business focus and automation relevance\n            business_score = profile.get('business_focus', 0) * 0.6\n            automation_score = profile.get('automation_relevance', 0) * 0.4\n            \n            # Adjust for activity level\n            activity_multiplier = {\n                'high': 1.2,\n                'medium': 1.0,\n                'low': 0.8\n            }.get(profile.get('activity_level', 'medium'), 1.0)\n            \n            # Adjust for member count (sweet spot around 100k-500k)\n            member_count = profile.get('member_count', 100000)\n            if 50000 <= member_count <= 500000:\n                size_multiplier = 1.1\n            elif member_count > 1000000:\n                size_multiplier = 0.9  # Too big, less personal interaction\n            else:\n                size_multiplier = 1.0\n            \n            opportunity_score = (business_score + automation_score) * activity_multiplier * size_multiplier\n            opportunity_scores[subreddit] = min(1.0, opportunity_score)\n        \n        return opportunity_scores\n    \n    def _generate_recommendation_candidates(self, user_profile: Dict, landscape_analysis: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Generate candidate recommendations\"\"\"\n        candidates = []\n        \n        # Generate similarity-based recommendations\n        similarity_candidates = self._generate_similarity_recommendations(user_profile)\n        candidates.extend(similarity_candidates)\n        \n        # Generate trending-based recommendations\n        trending_candidates = self._generate_trending_recommendations(landscape_analysis)\n        candidates.extend(trending_candidates)\n        \n        # Generate discovery recommendations (explore new categories)\n        discovery_candidates = self._generate_discovery_recommendations(user_profile)\n        candidates.extend(discovery_candidates)\n        \n        # Remove duplicates\n        seen_subreddits = set()\n        unique_candidates = []\n        for candidate in candidates:\n            if candidate['name'] not in seen_subreddits:\n                unique_candidates.append(candidate)\n                seen_subreddits.add(candidate['name'])\n        \n        return unique_candidates\n    \n    def _generate_similarity_recommendations(self, user_profile: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations based on similarity to user preferences\"\"\"\n        recommendations = []\n        user_subreddits = set(user_profile.get('subreddit_preferences', {}).keys())\n        \n        for subreddit, profile in self.subreddit_profiles.items():\n            if subreddit in user_subreddits:\n                continue  # Skip subreddits user already knows\n            \n            # Calculate similarity score\n            similarity = self._calculate_subreddit_similarity(subreddit, user_profile)\n            \n            if similarity >= self.config['similarity_threshold']:\n                recommendations.append({\n                    'name': subreddit,\n                    'type': 'similarity',\n                    'similarity_score': similarity,\n                    'profile': profile,\n                    'reason': f\"Similar to your interests in {', '.join(list(user_subreddits)[:2])}\"\n                })\n        \n        return recommendations\n    \n    def _calculate_subreddit_similarity(self, subreddit: str, user_profile: Dict) -> float:\n        \"\"\"Calculate similarity between subreddit and user profile\"\"\"\n        if subreddit not in self.subreddit_profiles:\n            return 0.0\n        \n        subreddit_profile = self.subreddit_profiles[subreddit]\n        \n        # Category similarity\n        subreddit_category = subreddit_profile.get('category', 'general')\n        category_preference = user_profile.get('category_preferences', {}).get(subreddit_category, 0)\n        \n        # Topic similarity\n        subreddit_topics = set(subreddit_profile.get('typical_problems', []))\n        user_topics = set(user_profile.get('topic_preferences', {}).keys())\n        topic_overlap = len(subreddit_topics.intersection(user_topics)) / max(len(subreddit_topics.union(user_topics)), 1)\n        \n        # Business focus alignment\n        business_alignment = abs(subreddit_profile.get('business_focus', 0.5) - user_profile.get('business_focus', 0.5))\n        business_similarity = 1 - business_alignment\n        \n        # Automation interest alignment\n        automation_alignment = abs(subreddit_profile.get('automation_relevance', 0.5) - user_profile.get('automation_interest', 0.5))\n        automation_similarity = 1 - automation_alignment\n        \n        # Weighted combination\n        similarity = (\n            category_preference * 0.3 +\n            topic_overlap * 0.3 +\n            business_similarity * 0.2 +\n            automation_similarity * 0.2\n        )\n        \n        return min(1.0, similarity)\n    \n    def _generate_trending_recommendations(self, landscape_analysis: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations based on trending topics\"\"\"\n        recommendations = []\n        trending_topics = landscape_analysis.get('trending_topics', [])\n        opportunity_scores = landscape_analysis.get('opportunity_scores', {})\n        \n        # Find subreddits related to trending topics\n        for topic_data in trending_topics[:3]:  # Top 3 trending topics\n            topic = topic_data['topic'].lower()\n            \n            for subreddit, profile in self.subreddit_profiles.items():\n                typical_problems = [p.lower() for p in profile.get('typical_problems', [])]\n                \n                if any(topic in problem or problem in topic for problem in typical_problems):\n                    opportunity_score = opportunity_scores.get(subreddit, 0.5)\n                    \n                    recommendations.append({\n                        'name': subreddit,\n                        'type': 'trending',\n                        'trending_topic': topic_data['topic'],\n                        'growth_rate': topic_data['growth_rate'],\n                        'opportunity_score': opportunity_score,\n                        'profile': profile,\n                        'reason': f\"Growing interest in {topic_data['topic']} (+{topic_data['growth_rate']:.0%})\"\n                    })\n        \n        return recommendations\n    \n    def _generate_discovery_recommendations(self, user_profile: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Generate discovery recommendations for exploring new areas\"\"\"\n        recommendations = []\n        user_categories = set(user_profile.get('category_preferences', {}).keys())\n        \n        # Find subreddits in different categories\n        for subreddit, profile in self.subreddit_profiles.items():\n            subreddit_category = profile.get('category', 'general')\n            \n            if subreddit_category not in user_categories:\n                # Calculate discovery score\n                business_relevance = profile.get('business_focus', 0)\n                automation_relevance = profile.get('automation_relevance', 0)\n                discovery_score = (business_relevance + automation_relevance) / 2\n                \n                if discovery_score >= 0.6:  # Only high-quality discoveries\n                    recommendations.append({\n                        'name': subreddit,\n                        'type': 'discovery',\n                        'discovery_score': discovery_score,\n                        'new_category': subreddit_category,\n                        'profile': profile,\n                        'reason': f\"Explore {subreddit_category} opportunities\"\n                    })\n        \n        return recommendations\n    \n    def _rank_recommendations(self, candidates: List[Dict], user_profile: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Rank recommendation candidates\"\"\"\n        for candidate in candidates:\n            # Calculate final score based on type and metrics\n            base_score = 0.5\n            \n            if candidate['type'] == 'similarity':\n                base_score = candidate.get('similarity_score', 0.5) * 0.8\n            elif candidate['type'] == 'trending':\n                growth_bonus = min(0.3, candidate.get('growth_rate', 0))\n                opportunity_bonus = candidate.get('opportunity_score', 0.5) * 0.3\n                base_score = 0.6 + growth_bonus + opportunity_bonus\n            elif candidate['type'] == 'discovery':\n                base_score = candidate.get('discovery_score', 0.5) * 0.7\n            \n            # Add popularity and relevance adjustments\n            profile = candidate.get('profile', {})\n            popularity_score = min(1.0, math.log10(profile.get('member_count', 10000) / 10000 + 1))\n            relevance_score = profile.get('business_focus', 0.5)\n            \n            final_score = (\n                base_score * 0.6 +\n                popularity_score * self.config['popularity_weight'] +\n                relevance_score * self.config['relevance_weight']\n            )\n            \n            candidate['final_score'] = final_score\n            candidate['confidence'] = min(1.0, final_score + 0.1)  # Slight confidence boost\n        \n        # Sort by final score\n        return sorted(candidates, key=lambda x: x['final_score'], reverse=True)\n    \n    def _add_recommendation_explanations(self, recommendations: List[Dict], user_profile: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Add detailed explanations to recommendations\"\"\"\n        explained_recommendations = []\n        \n        for i, rec in enumerate(recommendations):\n            profile = rec.get('profile', {})\n            \n            # Calculate match percentage\n            match_percentage = int(rec.get('confidence', 0.7) * 100)\n            \n            explained_rec = {\n                'name': rec['name'],\n                'display_name': f\"r/{rec['name']}\",\n                'match_percentage': match_percentage,\n                'confidence': rec.get('confidence', 0.7),\n                'recommendation_type': rec['type'],\n                'reason': rec.get('reason', 'Recommended for you'),\n                \n                # Subreddit info\n                'member_count': profile.get('member_count', 0),\n                'activity_level': profile.get('activity_level', 'medium'),\n                'category': profile.get('category', 'general'),\n                'description': self._generate_subreddit_description(rec['name'], profile),\n                \n                # Business metrics\n                'business_focus': profile.get('business_focus', 0.5),\n                'automation_relevance': profile.get('automation_relevance', 0.5),\n                'opportunity_score': rec.get('opportunity_score', profile.get('business_focus', 0.5)),\n                \n                # Ranking\n                'rank': i + 1,\n                'badge': self._get_recommendation_badge(rec),\n                'explanation': self._generate_detailed_explanation(rec, user_profile)\n            }\n            \n            explained_recommendations.append(explained_rec)\n        \n        return explained_recommendations\n    \n    def _generate_subreddit_description(self, subreddit_name: str, profile: Dict) -> str:\n        \"\"\"Generate a description for the subreddit\"\"\"\n        category = profile.get('category', 'general')\n        problems = profile.get('typical_problems', [])\n        member_count = profile.get('member_count', 0)\n        \n        # Format member count\n        if member_count >= 1000000:\n            members_str = f\"{member_count / 1000000:.1f}M members\"\n        elif member_count >= 1000:\n            members_str = f\"{member_count // 1000}K members\"\n        else:\n            members_str = f\"{member_count} members\"\n        \n        activity = profile.get('activity_level', 'medium')\n        activity_desc = {\n            'high': 'Very Active',\n            'medium': 'Active',\n            'low': 'Growing'\n        }.get(activity, 'Active')\n        \n        problem_desc = \"\"\n        if problems:\n            if len(problems) == 1:\n                problem_desc = f\" Community focused on {problems[0]}.\"\n            else:\n                problem_desc = f\" Discusses {', '.join(problems[:2])} and related topics.\"\n        \n        return f\"{members_str} • {activity_desc}.{problem_desc}\"\n    \n    def _get_recommendation_badge(self, rec: Dict) -> str:\n        \"\"\"Get badge for recommendation\"\"\"\n        rec_type = rec.get('type')\n        confidence = rec.get('confidence', 0.5)\n        \n        if rec_type == 'trending':\n            return 'TRENDING'\n        elif rec_type == 'discovery':\n            return 'NEW'\n        elif confidence > 0.8:\n            return 'RECOMMENDED'\n        else:\n            return 'SUGGESTED'\n    \n    def _generate_detailed_explanation(self, rec: Dict, user_profile: Dict) -> str:\n        \"\"\"Generate detailed explanation for recommendation\"\"\"\n        rec_type = rec.get('type')\n        \n        if rec_type == 'similarity':\n            return f\"This subreddit aligns with your interests and has similar discussions to communities you engage with.\"\n        elif rec_type == 'trending':\n            topic = rec.get('trending_topic', 'popular topics')\n            growth = rec.get('growth_rate', 0)\n            return f\"Growing community discussing {topic} with {growth:.0%} increase in activity.\"\n        elif rec_type == 'discovery':\n            category = rec.get('new_category', 'new area')\n            return f\"Expand into {category} opportunities with high business potential.\"\n        else:\n            return \"Recommended based on your activity and interests.\"\n    \n    def _get_fallback_recommendations(self, count: int) -> List[Dict[str, Any]]:\n        \"\"\"Get fallback recommendations when main algorithm fails\"\"\"\n        fallback_subreddits = [\n            {\n                'name': 'entrepreneur',\n                'display_name': 'r/entrepreneur',\n                'match_percentage': 85,\n                'confidence': 0.85,\n                'reason': 'High business opportunity density',\n                'member_count': 1200000,\n                'activity_level': 'high',\n                'category': 'business',\n                'description': '1.2M members • Very Active. Startup and business discussions.',\n                'badge': 'RECOMMENDED'\n            },\n            {\n                'name': 'smallbusiness',\n                'display_name': 'r/smallbusiness',\n                'match_percentage': 82,\n                'confidence': 0.82,\n                'reason': 'Small business automation opportunities',\n                'member_count': 800000,\n                'activity_level': 'high',\n                'category': 'business',\n                'description': '800K members • Very Active. Small business challenges and solutions.',\n                'badge': 'RECOMMENDED'\n            }\n        ]\n        \n        return fallback_subreddits[:count]\n    \n    def track_user_interaction(self, user_id: str, interaction_data: Dict):\n        \"\"\"Track user interaction for recommendation improvement\"\"\"\n        try:\n            interaction = {\n                'timestamp': datetime.now().isoformat(),\n                'type': interaction_data.get('type', 'view'),\n                'subreddit': interaction_data.get('subreddit'),\n                'post_id': interaction_data.get('post_id'),\n                'business_score': interaction_data.get('business_score', 0),\n                'duration': interaction_data.get('duration', 0),\n                'action': interaction_data.get('action')  # 'upvote', 'save', 'comment', etc.\n            }\n            \n            self.user_interactions[user_id].append(interaction)\n            \n            # Keep only recent interactions (last 30 days)\n            cutoff_date = datetime.now() - timedelta(days=30)\n            self.user_interactions[user_id] = [\n                i for i in self.user_interactions[user_id]\n                if datetime.fromisoformat(i['timestamp']) > cutoff_date\n            ]\n            \n            # Clear recommendation cache for this user\n            keys_to_remove = [k for k in self.recommendation_cache.keys() if k.startswith(user_id)]\n            for key in keys_to_remove:\n                del self.recommendation_cache[key]\n            \n            self.logger.debug(f\"Tracked interaction for user {user_id}: {interaction['type']}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to track user interaction: {e}\")\n    \n    def get_trending_topics(self, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"Get trending topics for the specified time window\"\"\"\n        cache_key = f\"trending_{hours}h\"\n        \n        if cache_key in self.trending_cache:\n            cached_result = self.trending_cache[cache_key]\n            if (datetime.now() - cached_result['generated_at']).seconds < 1800:  # 30 min cache\n                return cached_result['topics']\n        \n        try:\n            # Get trending topics (this would analyze recent posts in real implementation)\n            trending_topics = self._get_trending_topics()\n            \n            self.trending_cache[cache_key] = {\n                'topics': trending_topics,\n                'generated_at': datetime.now()\n            }\n            \n            return trending_topics\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to get trending topics: {e}\")\n            return []\n    \n    def get_recommendation_analytics(self, user_id: str = \"default\") -> Dict[str, Any]:\n        \"\"\"Get analytics about recommendations\"\"\"\n        try:\n            user_profile = self._build_user_profile(user_id)\n            \n            return {\n                'user_id': user_id,\n                'total_interactions': user_profile.get('interaction_count', 0),\n                'business_focus_score': user_profile.get('business_focus', 0),\n                'automation_interest_score': user_profile.get('automation_interest', 0),\n                'top_categories': list(user_profile.get('category_preferences', {}).keys())[:3],\n                'top_topics': list(user_profile.get('topic_preferences', {}).keys())[:5],\n                'recommendation_cache_size': len([k for k in self.recommendation_cache.keys() if k.startswith(user_id)]),\n                'last_profile_update': user_profile.get('last_updated'),\n                'subreddit_coverage': len(self.subreddit_profiles),\n                'algorithm_version': '1.0'\n            }\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to get recommendation analytics: {e}\")\n            return {\n                'user_id': user_id,\n                'error': str(e),\n                'algorithm_version': '1.0'\n            }\n    \n    def update_subreddit_profile(self, subreddit: str, profile_data: Dict):\n        \"\"\"Update profile for a subreddit\"\"\"\n        if subreddit in self.subreddit_profiles:\n            self.subreddit_profiles[subreddit].update(profile_data)\n        else:\n            self.subreddit_profiles[subreddit] = profile_data\n        \n        # Clear related caches\n        self.recommendation_cache.clear()\n        \n        self.logger.info(f\"Updated profile for r/{subreddit}\")\n    \n    def clear_cache(self, cache_type: Optional[str] = None):\n        \"\"\"Clear recommendation caches\"\"\"\n        if cache_type == 'recommendations' or cache_type is None:\n            self.recommendation_cache.clear()\n        \n        if cache_type == 'trending' or cache_type is None:\n            self.trending_cache.clear()\n        \n        self.logger.info(f\"Cleared {cache_type or 'all'} caches\")\n    \n    def close(self):\n        \"\"\"Clean up recommendation service\"\"\"\n        self.clear_cache()\n        self.user_interactions.clear()\n        \n        self.logger.info(\"AI Recommendation service closed\")